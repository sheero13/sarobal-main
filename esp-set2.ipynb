{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('image_path', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# 1. Constructing a Scale Space\n",
    "# Detect SIFT features and compute descriptors\n",
    "# (Scale space construction is handled internally by the SIFT algorithm)\n",
    "keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "\n",
    "# Draw keypoints for visualization\n",
    "image_with_keypoints = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display original image with keypoints\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image_with_keypoints, cmap='gray')\n",
    "plt.title('SIFT Keypoints')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 2. Key Point Localization\n",
    "# Display number of keypoints detected\n",
    "print(f\"Number of keypoints detected: {len(keypoints)}\")\n",
    "\n",
    "# Print the coordinates of some keypoints (up to 5 for illustration)\n",
    "print(\"Keypoint Coordinates (x, y):\")\n",
    "for i, kp in enumerate(keypoints[:5]):\n",
    "    print(f\"Keypoint {i+1}: ({kp.pt[0]}, {kp.pt[1]})\")\n",
    "\n",
    "# 3. Orientation Assignment\n",
    "# Each keypoint has an angle attribute representing the orientation\n",
    "print(\"\\nOrientation of keypoints:\")\n",
    "for i, kp in enumerate(keypoints[:5]):\n",
    "    print(f\"Keypoint {i+1}: Orientation = {kp.angle} degrees\")\n",
    "\n",
    "# 4. Key Point Descriptor\n",
    "# Each keypoint has a descriptor that is a vector describing the neighborhood\n",
    "# Display the descriptor of the first keypoint as an example\n",
    "print(\"\\nDescriptor of first keypoint:\")\n",
    "print(descriptors[0])\n",
    "\n",
    "# Number of features per descriptor vector\n",
    "print(f\"\\nLength of each descriptor vector: {descriptors.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download cfg file: https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download weight file: https://www.kaggle.com/datasets/shivam316/yolov3-weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download coco.names file: https://www.kaggle.com/datasets/rajeevsinghsisodiya/yolo-model-and-configuration-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "net = cv2.dnn.readNet(\"weight_file_path\", \"cfg_file_path\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
    "\n",
    "with open(\"coco_name_file_path\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "img = cv2.imread(\"input_image_path\")\n",
    "height, width, channels = img.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        color = (0, 255, 0)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, label, (x, y - 5), font, 1, color, 2)\n",
    "\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
